<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>Session-based Recommendation with Graph Neural Networks</title><style>
/* cspell:disable-file */
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	text-indent: -1.7em;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

.simple-table {
	margin-top: 1em;
	font-size: 0.875rem;
}

.simple-table-header {
	background: rgb(247, 246, 243);
	color: black;
	font-weight: 500;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1.25em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.highlight-default {
	color: rgba(55, 53, 47, 1);
}
.highlight-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(145, 145, 142, 1);
}
.highlight-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(187, 132, 108, 1);
}
.highlight-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(215, 129, 58, 1);
}
.highlight-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 148, 51, 1);
}
.highlight-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(108, 155, 125, 1);
}
.highlight-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(91, 151, 189, 1);
}
.highlight-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(167, 130, 195, 1);
}
.highlight-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(205, 116, 159, 1);
}
.highlight-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(225, 111, 100, 1);
}
.highlight-gray_background {
	background: rgba(241, 241, 239, 1);
}
.highlight-brown_background {
	background: rgba(244, 238, 238, 1);
}
.highlight-orange_background {
	background: rgba(251, 236, 221, 1);
}
.highlight-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.highlight-teal_background {
	background: rgba(237, 243, 236, 1);
}
.highlight-blue_background {
	background: rgba(231, 243, 248, 1);
}
.highlight-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.highlight-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.highlight-red_background {
	background: rgba(253, 235, 236, 1);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(145, 145, 142, 1);
}
.block-color-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(187, 132, 108, 1);
}
.block-color-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(215, 129, 58, 1);
}
.block-color-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 148, 51, 1);
}
.block-color-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(108, 155, 125, 1);
}
.block-color-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(91, 151, 189, 1);
}
.block-color-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(167, 130, 195, 1);
}
.block-color-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(205, 116, 159, 1);
}
.block-color-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(225, 111, 100, 1);
}
.block-color-gray_background {
	background: rgba(241, 241, 239, 1);
}
.block-color-brown_background {
	background: rgba(244, 238, 238, 1);
}
.block-color-orange_background {
	background: rgba(251, 236, 221, 1);
}
.block-color-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.block-color-teal_background {
	background: rgba(237, 243, 236, 1);
}
.block-color-blue_background {
	background: rgba(231, 243, 248, 1);
}
.block-color-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.block-color-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.block-color-red_background {
	background: rgba(253, 235, 236, 1);
}
.select-value-color-pink { background-color: rgba(245, 224, 233, 1); }
.select-value-color-purple { background-color: rgba(232, 222, 238, 1); }
.select-value-color-green { background-color: rgba(219, 237, 219, 1); }
.select-value-color-gray { background-color: rgba(227, 226, 224, 1); }
.select-value-color-orange { background-color: rgba(250, 222, 201, 1); }
.select-value-color-brown { background-color: rgba(238, 224, 218, 1); }
.select-value-color-red { background-color: rgba(255, 226, 221, 1); }
.select-value-color-yellow { background-color: rgba(253, 236, 200, 1); }
.select-value-color-blue { background-color: rgba(211, 229, 239, 1); }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="c37b0e90-353b-4f20-b392-fa072a7a1937" class="page sans"><header><h1 class="page-title">Session-based Recommendation with Graph Neural Networks</h1></header><div class="page-body"><p id="26c0dda4-ff80-4b81-a35b-8139be822df2" class="">Session-based recommendation tasks are performed based on the user&#x27;s anonymous historical behavior sequence and implicit feedback data, such as clicks, browsing, purchasing, etc., rather than rating or comment data. The primary aim is to predict the next behavior based on a sequence of the historical sequence of the session. Session-based recommendation aims to predict which item a user will click next, solely based on the user’s current sequential session data without access to the long-term preference profile.</p><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="1a2d440b-e7e4-498b-8b7c-3771380ad719"><div style="font-size:1.5em"><span class="icon">☝🏼</span></div><div style="width:100%">Session-based recommenders are gaining popularity due to user privacy concerns. </div></figure><p id="c4486481-d8bd-4996-824d-b90de773feb0" class="">The input to these systems are time-ordered logs of recorded user interactions, where the interactions are grouped into sessions. Such a session could, for example, correspond to a listening session on a music service, or a shopping session on an e-commerce site. One particularity of such approaches is that users are anonymous, which is a common problem on websites that deal with first-time users or users that are not logged in. The prediction task in this setting is to predict the next user action, given only the interactions of the ongoing session. Today, session-based recommendation is a highly active research area due to its practical relevance.</p><figure id="91a6a429-96db-4e52-b996-402c9fa57cc3" class="image"><a href="Session-based%20Recommendation%20with%20Graph%20Neural%20Net%2091a6a42996db4e52b996402c9fa57cc3/Untitled.png"><img style="width:672px" src="Session-based%20Recommendation%20with%20Graph%20Neural%20Net%2091a6a42996db4e52b996402c9fa57cc3/Untitled.png"/></a></figure><p id="15031f39-59b9-4e70-a1f2-ff1bb2a5dcd5" class="">Some of the major reason for the effectiveness and the growing popularity of session-based recommenders are: 1) Cookies and browser fingerprinting can not always recognize users correctly, especially across different devices and platforms, 2) Opt-out users are not tracked across sessions, 3) Privacy concerns for opt-in users, 4) Infrequent user visits, cookie expiration - Users visiting a site infrequently can not be recognized over long time, 5) Changing user intent across sessions - On many domains, users have session-based traits (short video sites, marketplaces, classified sites, etc.), and 6) Earlier solutions for handling sessions was only based on last user click and ignored user interactions in the session.</p><p id="f9b06c88-7b9b-4865-a571-7bac2b21df23" class="">Session-based recommendation is an important task for domains such as e-commerce, news, streaming video and music services, where users might be untraceable, their histories can be short, and users can have rapidly changing tastes. Providing recommendations based purely on the interactions that happen in the current session.</p><p id="ed140a72-7d68-4cd8-b298-a00b309ad7bf" class="">But the problem of session-based recommendation aims to predict user actions based on anonymous sessions. Previous methods model a session as a sequence and estimate user representations besides item representations to make recommendations. Though achieved promising results, they are insufficient to obtain accurate user vectors in sessions and neglect complex transitions of items.</p><p id="9a357c94-758f-4d5d-815b-4d9ab5877bc7" class="">Session-based recommendations are challenging due to limited user-item interactions. Typical sequential models are not able to capture complex patterns from all previous interactions.</p><p id="6cf619de-2657-47b4-bce0-f0cf7c913a41" class="">GNNs offer an intuitive approach to session-based recommendation since each session can be mapped into a graph’s chain. Each node of the graph represents an item, and each edge represents the interactions. The natural compatibility between data modeled in such a manner and GNNs allow this method to perform well.</p><p id="784bb8d5-1db6-47ac-a193-54a43833082c" class="">Here is the general framework of session-based recommendations using GNNs:</p><figure id="851cfcd8-2593-4fd1-bef6-363b4f4f5274" class="image"><a href="Session-based%20Recommendation%20with%20Graph%20Neural%20Net%2091a6a42996db4e52b996402c9fa57cc3/Untitled%201.png"><img style="width:720px" src="Session-based%20Recommendation%20with%20Graph%20Neural%20Net%2091a6a42996db4e52b996402c9fa57cc3/Untitled%201.png"/></a></figure><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="b69e5c79-3968-4180-bd88-f4b135182a81"><div style="font-size:1.5em"><span class="icon">☝🏼</span></div><div style="width:100%">Representation of session with Graph neural networks was first introduced in the <strong>SR-GNN</strong> paper. In this method, session sequences are modeled as graph-structured data. Based on the session graph, GNN can capture complex transitions of items, which are difficult to be revealed by previous conventional sequential methods. Each session is then represented as the composition of the global preference and the current interest of that session using an attention network.</div></figure><h2 id="4324be27-d2fd-410c-9198-2f76a6407ff8" class="">Datasets</h2><p id="accad1f1-492d-4f2e-afe0-0a556e530ba1" class="">Session data has many important characteristics:</p><ul id="54c571b8-7670-4389-aaa7-b73103e635dc" class="bulleted-list"><li style="list-style-type:disc">Session clicks and navigation are sequential by nature. The order of clicks as well as the navigational path may contain information about user intent.</li></ul><ul id="0c1bd3e4-4502-44b6-a011-204e015857ce" class="bulleted-list"><li style="list-style-type:disc">Viewed items often have metadata such as names, categories, and descriptions, which provides information about the user’s tastes and what they are looking for.</li></ul><ul id="03ccb583-d6a9-4b28-bf5c-7c8215168d13" class="bulleted-list"><li style="list-style-type:disc">Sessions are limited in time and scope. A session has a specific goal and generally ends once that goal is accomplished: rent a hotel for a business trip, find a restaurant for a romantic date, and so on. This means that the session has intrinsic informational power related to a specific item (such as the hotel or restaurant that’s eventually booked).</li></ul><h3 id="6bb19e31-117d-4d3e-9d0c-dc404ec02709" class="">Diginetica</h3><p id="a4a5c991-9d3a-43ce-889e-2c8a1f40f8df" class="">Diginetica is a dataset that comes from CIKM Cup 2016. Its transaction data is suitable for session-based recommendation.</p><h3 id="b3347ce0-9045-4395-bb22-3ae590459539" class="">Yoochoose</h3><p id="ce5f00bf-29dd-4761-91bd-4b8bc8d287fa" class="">The dataset is session-based and each session contains a sequence of clicks and purchases. Since the Yoochoose dataset is too large, in some cases we only use its the most recent 1/64 fractions of the training sessions, denoted as Yoochoose 1/64.</p><h2 id="ab0bec60-9be2-45a8-bfe6-7c085ed4772e" class="">Preprocessing</h2><p id="88e9e698-be67-43e7-93d5-252234a8975d" class="">In general, we do the following preprocessing operations on the sessions data - </p><ol type="1" id="b1508473-33a0-4f8a-98f4-822737dba432" class="numbered-list" start="1"><li>Drop all unit-length sessions.</li></ol><ol type="1" id="f29ee7b2-9135-4f09-a450-cd11ce1adbf5" class="numbered-list" start="2"><li>Remove items with less than <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span></span><span>﻿</span></span> interactions.</li></ol><ol type="1" id="49ad042c-7916-46ec-9bdc-59760a271e08" class="numbered-list" start="3"><li>Remove items that appear less than <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">n</span></span></span></span></span><span>﻿</span></span> no. of times.</li></ol><ol type="1" id="88260eed-579c-40c3-971a-0653d9909336" class="numbered-list" start="4"><li>Take session of last <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">x</span></span></span></span></span><span>﻿</span></span> days/weeks as test set.</li></ol><ol type="1" id="24b7cbe6-112a-41eb-a3c6-836d0faf4c68" class="numbered-list" start="5"><li>For an existing session, generate a series of input session sequences and corresponding labels.</li></ol><ol type="1" id="6add8c8d-e4f1-4fec-951e-f5f03445e159" class="numbered-list" start="6"><li>Filter out items from the test set which do not appear in the training set.</li></ol><ol type="1" id="284f999f-fc5a-4447-be58-4d6af53e5f21" class="numbered-list" start="7"><li>Keep only <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span></span><span>﻿</span></span> most popular items/users.</li></ol><ol type="1" id="4f1fd64b-6d13-47bf-b3aa-256a90673a66" class="numbered-list" start="8"><li>Partition the log into sessions by applying user inactivity threshold of time duration <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.61508em;vertical-align:0em;"></span><span class="mord mathnormal">t</span></span></span></span></span><span>﻿</span></span>.</li></ol><ol type="1" id="bd442b6c-01b0-48c8-a239-95e16bae4f78" class="numbered-list" start="9"><li>Replace multiple consecutive clicks (or in general, event) on the same item by a single click on that item.</li></ol><h2 id="cf52aa10-e2c3-4084-a378-83c7d622f9fb" class="">Methods</h2><h3 id="2f4a5e55-b51f-46a9-9b5a-a821fc1172bc" class="">Baseline methods</h3><table id="83331eb8-4895-412a-88c6-541cba0e8fff" class="simple-table"><thead><tr id="6ef35eb8-ef10-4ea1-8868-b87794808a90"><th id="Zx]T" class="simple-table-header">Model</th><th id="Ys|q" class="simple-table-header">Description</th></tr></thead><tbody><tr id="5561dcca-c9af-4f9d-b095-6063ec4378b8"><td id="Zx]T">Item-KNN</td><td id="Ys|q">Item-KNN is a neighborhood method that recommends items that are similar to the previous items in the current session, where the similarity between two items is defined by their cosine similarity.</td></tr><tr id="b55f0392-1deb-4f41-9013-dbe006f13331"><td id="Zx]T">Markov Chain</td><td id="Ys|q">Markov chains predicts the user’s next action solely based on the previous action. But such a strong independence assumption suffers from noisy data.</td></tr><tr id="454cc6dd-a1f1-4c1d-bbc2-5f65945f7af0"><td id="Zx]T">FPMC</td><td id="Ys|q">FPMC is a Markov-chain based method for next-basket recommendation. To adapt it for session-based recommendation, we consider the next item as the next basket.</td></tr><tr id="4848efe9-8aa9-4db6-82f6-cc28bd232280"><td id="Zx]T">GRU4Rec</td><td id="Ys|q">GRU4Rec models short-term preferences with gated recurrent units (GRUs).</td></tr><tr id="80aa0ef3-d432-48f1-b8b3-aefe151784cb"><td id="Zx]T">NARM</td><td id="Ys|q">NARM employs RNNs with attention to capture user’s main purposes and sequential behaviors. Two RNN-based subsystems to capture users’ local and global preference respectively.</td></tr><tr id="04625d44-8be6-4fae-a673-4637fd0520f9"><td id="Zx]T">STAMP</td><td id="Ys|q">STAMP extracts users’ potential interests using a simple multilayer perceptron model and an attentive network.</td></tr><tr id="3f96f35f-1068-4904-8291-3dd5e91757ce"><td id="Zx]T">NextItNet</td><td id="Ys|q">NextItNet is a CNN-based method for next-item recommendation. It uses dilated convolution to increase the receptive fields without using the lossy pooling operations.</td></tr></tbody></table><h3 id="59c6b094-6462-40cf-b9f4-8ac944170ea1" class="">GNN-based methods</h3><table id="4c62edb8-c10a-453a-9f80-3e89ee88d996" class="simple-table"><thead><tr id="d72e1e85-0eed-420e-ae88-3f83f5bc77c7"><th id="Zx]T" class="simple-table-header">Model</th><th id="Ys|q" class="simple-table-header">Description</th></tr></thead><tbody><tr id="f24d8096-9bda-480d-b351-e396d9f8b09a"><td id="Zx]T">SR-GNN</td><td id="Ys|q">SR-GNN first models all session sequences as session graphs. Then, each session graph is proceeded one by one and the resulting node vectors can be obtained through a gated graph neural network. After that, each session is represented as the combination of the global preference and current interests of this session using an attention net. Finally, it predict the probability of each item that will appear to be the next-click one for each session.</td></tr><tr id="c04ec833-b92c-4306-9743-3fb5f93ca51a"><td id="Zx]T">GC-SAN</td><td id="Ys|q">GC-SAN uses a GGNN to extract local context information and a self-attention network (SAN) to capture global dependencies between distant positions.</td></tr><tr id="c4987161-13a4-43f2-b1ae-2169e38dc141"><td id="Zx]T">FGNN</td><td id="Ys|q">FGNN converts a session into a weighted directed graph where the edge weights are the counts of item transitions. An adapted multi-layered graph attention network (GAT) is used to extract item features and a modified Set2Set pooling operator is applied to generate session representations.</td></tr><tr id="bd1cac03-12a7-46de-b73a-4cfef4629116"><td id="Zx]T">LESSR</td><td id="Ys|q">Given a session, LESSR compute an edge-order preserving (EOP) multigraph and a shortcut graph. The graphs and the node representations are passed as input to multiple interleaved EOPA and SGAT layers. Each layer outputs the new node representations. The readout layer computes a graph-level representation, which is combined with the recent interests to form the session embedding. Finally, the prediction layer computes the probability distribution of the next item.</td></tr><tr id="b5a1cc37-c75a-4096-a7be-c24304b5bc72"><td id="Zx]T">GCE_GNN</td><td id="Ys|q">GCE-GNN first construct a global graph based on all training session sequences. Then for each session, a global feature encoder and local feature encoder is used to extract node feature with global context and local context. Then the model incorporates position information to learn the contribution of each item to the next predicted item. Finally, candidate items are scored.</td></tr><tr id="539e749f-53ba-4888-8ad9-887558907ff3"><td id="Zx]T">DGTN</td><td id="Ys|q">DGTN propagate the embeddings of neighbor items in the target session and the neighbor session set towards the next layer in the intra- and intersession channel, respectively. Then the embeddings of the final layer in the two channels are fed into the fusion function to obtain the final item embedding. Based on the learned item embeddings, it generate the session embedding via session pooling. Finally, a prediction layer is applied to generate the recommendation probability.</td></tr><tr id="1bb10d0f-f38b-453c-8fe7-f3f2ce3550c3"><td id="Zx]T">TAGNN</td><td id="Ys|q">TAGNN first models all session sequences as session graphs. Then, graph neural networks capture rich item transitions in sessions. Lastly, from one session embedding vector, target-aware attention adaptively activates different user interests concerning varied target items to be predicted.</td></tr><tr id="a0d08a1b-4040-400b-9465-49665f210d7b"><td id="Zx]T">TAGNN++</td><td id="Ys|q">TAGNN models item interactions with GNN, and both local and global user interactions with  a Transformer.</td></tr></tbody></table><h2 id="b43b343a-a394-4c97-9f45-8df9a0a60035" class="">SR-GNN</h2><p id="afb7ad20-895a-4d39-afc9-78daf48a8690" class=""><a href="https://arxiv.org/abs/1811.00855"><em>Wu et. al. Session-based Recommendation with Graph Neural Networks. AAAI, 2019.</em></a></p><p id="a1af3322-25ea-4255-8532-acf23bd7ac50" class="">SR-GNN first models all session sequences as session graphs. Then, each session graph is proceeded one by one and the resulting node vectors can be obtained through a gated graph neural network. After that, each session is represented as the combination of the global preference and current interests of this session using an attention net. Finally, it predict the probability of each item that will appear to be the next-click one for each session.</p><figure id="d159a6d4-7d72-419c-bde8-0d5d9b8f25d0" class="image"><a href="Session-based%20Recommendation%20with%20Graph%20Neural%20Net%2091a6a42996db4e52b996402c9fa57cc3/Untitled%202.png"><img style="width:1270px" src="Session-based%20Recommendation%20with%20Graph%20Neural%20Net%2091a6a42996db4e52b996402c9fa57cc3/Untitled%202.png"/></a><figcaption>The workflow of the proposed SR-GNN method.</figcaption></figure><h2 id="e9ada538-9094-4e97-9e53-27c33f956481" class="">GC-SAN</h2><p id="903274ea-19ee-47bf-85cb-3eb5c2beb675" class=""><em><a href="https://www.ijcai.org/proceedings/2019/0547.pdf">Xu et. al. Graph Contextualized Self-Attention Network for Session-based Recommendation. IJCAI, 2019.</a></em></p><p id="7260aa07-ac5f-44ca-b6b2-c7c7ce927928" class="">Graph contextualized self-attention model (GC-SAN) utilizes both graph neural network and self-attention mechanism, for session-based recommendation. It dynamically construct a graph structure for session sequences and capture rich local dependencies via graph neural network (GNN). Then each session learns long-range dependencies by applying the self-attention mechanism. Finally, each session is represented as a linear combination of the global preference and the current interest of that session.</p><figure id="93bf5bf7-c374-4ff7-9aaa-c68fbd08f654" class="image"><a href="Session-based%20Recommendation%20with%20Graph%20Neural%20Net%2091a6a42996db4e52b996402c9fa57cc3/Untitled%203.png"><img style="width:1202px" src="Session-based%20Recommendation%20with%20Graph%20Neural%20Net%2091a6a42996db4e52b996402c9fa57cc3/Untitled%203.png"/></a></figure><h2 id="23953acc-36d4-48a1-89dc-56b4e3eacf7e" class="">FGNN</h2><p id="b73dad1e-d456-48cc-8d81-34797d68fe6d" class=""><a href="https://arxiv.org/abs/1911.11942"><em>Qiu et. al. Rethinking the Item Order in Session-based Recommendation with Graph Neural Networks. CIKM, 2019.</em></a></p><p id="c06b5383-dadf-40aa-8944-89860667a258" class="">FGNN converts a session into a weighted directed graph where the edge weights are the counts of item transitions. An adapted multi-layered graph attention network (GAT) is used to extract item features and a modified Set2Set pooling operator is applied to generate session representations.</p><h2 id="10959c3b-16d8-4d4f-abfb-05045f840233" class="">LESSR</h2><p id="c551dee0-8355-4512-aae4-8c16f0070b7d" class=""><a href="https://dl.acm.org/doi/pdf/10.1145/3394486.3403170"><em>T. Chen and R. Wong, Handling Information Loss of Graph Neural Networks for Session-based Recommendation. KDD, 2020.</em></a></p><p id="55b76031-7c38-45f9-bede-3f61cb5b28c3" class="">Given a session, LESSR compute an edge-order preserving (EOP) multigraph and a shortcut graph. The graphs and the node representations are passed as input to multiple interleaved EOPA and SGAT layers. Each layer outputs the new node representations. The readout layer computes a graph-level representation, which is combined with the recent interests to form the session embedding. Finally, the prediction layer computes the probability distribution of the next item.</p><h2 id="e7b978bc-db77-4343-a744-f87e3549e295" class="">GCE-GNN</h2><p id="b7c5c601-5771-4d48-9f5f-77a1cf30a9e3" class=""><a href="https://arxiv.org/abs/2106.05081"><em>Wang etl. al. Global Context Enhanced Graph Neural Networks for Session-based Recommendation. arXiv, 2021.</em></a></p><p id="1f9c3a29-be42-4d61-9c59-c089dc8e2f44" class="">GCE-GNN first construct a global graph based on all training session sequences. Then for each session, a global feature encoder and local feature encoder is used to extract node feature with global context and local context. Then the model incorporates position information to learn the contribution of each item to the next predicted item. Finally, candidate items are scored.</p><figure id="6f611619-4e72-47be-8c0f-cac4328b06e3" class="image"><a href="Session-based%20Recommendation%20with%20Graph%20Neural%20Net%2091a6a42996db4e52b996402c9fa57cc3/Untitled%204.png"><img style="width:1132px" src="Session-based%20Recommendation%20with%20Graph%20Neural%20Net%2091a6a42996db4e52b996402c9fa57cc3/Untitled%204.png"/></a><figcaption>An overview of the proposed framework.</figcaption></figure><h2 id="3ab07407-a1dc-400f-aad6-e4bf1081bd40" class="">DGTN</h2><p id="d5093817-626f-4437-a0f7-40ed1e94dc79" class=""><a href="https://arxiv.org/abs/2009.10002"><em>Zheng et. al. Dual-channel Graph Transition Network for Session-based Recommendation. arXiv, 2020.</em></a></p><p id="07beff60-b05c-48c5-a8d3-786e84dd66bd" class="">DGTN propagate the embeddings of neighbor items in the target session and the neighbor session set towards the next layer in the intra- and intersession channel, respectively. Then the embeddings of the final layer in the two channels are fed into the fusion function to obtain the final item embedding. Based on the learned item embeddings, it generate the session embedding via session pooling. Finally, a prediction layer is applied to generate the recommendation probability.</p><figure id="c509d13b-9da2-4f20-9604-83154b07e922" class="image"><a href="Session-based%20Recommendation%20with%20Graph%20Neural%20Net%2091a6a42996db4e52b996402c9fa57cc3/Untitled%205.png"><img style="width:432px" src="Session-based%20Recommendation%20with%20Graph%20Neural%20Net%2091a6a42996db4e52b996402c9fa57cc3/Untitled%205.png"/></a><figcaption>An illustration of the model architecture.</figcaption></figure><h2 id="f498e7ca-24fe-4fca-84cc-0348801bb4cb" class="">TAGNN</h2><p id="c73ac554-b1ce-495d-896d-5dc40c1ca5c8" class=""><em><a href="https://arxiv.org/abs/2005.02844">Yu et. al. Target Attentive Graph Neural Networks for Session-based Recommendation. SIGIR, 2020.</a></em></p><p id="cdba53a1-51bf-49d9-b215-5bb68021885b" class="">TAGNN first models all session sequences as session graphs. Then, graph neural networks capture rich item transitions in sessions. Lastly, from one session embedding vector, target-aware attention adaptively activates different user interests concerning varied target items to be predicted.</p><figure id="8ac73a57-a157-4619-8c58-5d315bc0a940" class="image"><a href="Session-based%20Recommendation%20with%20Graph%20Neural%20Net%2091a6a42996db4e52b996402c9fa57cc3/Untitled%206.png"><img style="width:528px" src="Session-based%20Recommendation%20with%20Graph%20Neural%20Net%2091a6a42996db4e52b996402c9fa57cc3/Untitled%206.png"/></a><figcaption>An overview of the proposed TAGNN method.</figcaption></figure><h2 id="bf62f921-11c0-4b2d-ab06-265ac24b32c0" class="">TAGNN++</h2><p id="86bd7f54-2a2a-4c69-9127-b6962f78ceb1" class=""><a href="https://arxiv.org/abs/2107.01516v2"><em>Mitheran et. al. Improved Representation Learning for Session-based Recommendation. arXiv, 2021.</em></a></p><p id="ab4a9d91-6966-44fc-8477-cc02b10320eb" class="">TAGNN models item interactions with GNN, and both local and global user interactions with  a Transformer.</p><figure id="5beca94d-f9cc-4e5a-a410-22cc8f287fdd" class="image"><a href="Session-based%20Recommendation%20with%20Graph%20Neural%20Net%2091a6a42996db4e52b996402c9fa57cc3/Untitled%207.png"><img style="width:288px" src="Session-based%20Recommendation%20with%20Graph%20Neural%20Net%2091a6a42996db4e52b996402c9fa57cc3/Untitled%207.png"/></a></figure><h2 id="f02c903e-fd99-4ffd-9399-f4565ce47e31" class="">Challenges</h2><p id="05f6ebf0-54ef-494f-ad0d-ba6654d387cf" class="">Despite the convenient representation of sessions offered by GNNs, it lacks the ability to model long-range dependencies and complicated interactions. One common issue is the lossy session encoding in which some sequential information about item transitions is ignored because of the lossy encoding from sessions to graphs and the permutation-invariant aggregation during message passing. Another common issue is the GNN&#x27;s ineffectiveness in capturing long-range dependencies within sessions due to the limited number of layers.</p><h3 id="a27cd1c3-da1b-4ff4-800e-c3342a095f22" class="">Lossy Session Encoding Problem</h3><p id="d2502073-bb3b-4030-acae-4da38f746328" class="">It is due to their lossy encoding schemes that convert sessions to graphs. To process sessions using a GNN, the sessions need to be converted to graphs first. In these methods, each session is converted to a directed graph whose nodes are the unique items in the session and the edges are the transitions between items. The edges can be either weighted or unweighted.</p><figure id="6d2ce81a-514b-4c8d-b0c7-854bbcb02f09" class="image"><a href="Session-based%20Recommendation%20with%20Graph%20Neural%20Net%2091a6a42996db4e52b996402c9fa57cc3/Untitled%208.png"><img style="width:263px" src="Session-based%20Recommendation%20with%20Graph%20Neural%20Net%2091a6a42996db4e52b996402c9fa57cc3/Untitled%208.png"/></a></figure><p id="9ac7e139-84cd-4193-b6bf-63ec9bee6f60" class="">Two different sessions [<style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>v</mi><mn>2</mn></msub><mo separator="true">,</mo><msub><mi>v</mi><mn>3</mn></msub><mo separator="true">,</mo><msub><mi>v</mi><mn>3</mn></msub><mo separator="true">,</mo><msub><mi>v</mi><mn>2</mn></msub><mo separator="true">,</mo><msub><mi>v</mi><mn>2</mn></msub><mo separator="true">,</mo><msub><mi>v</mi><mn>4</mn></msub></mrow><annotation encoding="application/x-tex">v_1, v_2, v_3, v_3, v_2, v_2, v_4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>] and [<style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>v</mi><mn>2</mn></msub><mo separator="true">,</mo><msub><mi>v</mi><mn>2</mn></msub><mo separator="true">,</mo><msub><mi>v</mi><mn>3</mn></msub><mo separator="true">,</mo><msub><mi>v</mi><mn>3</mn></msub><mo separator="true">,</mo><msub><mi>v</mi><mn>2</mn></msub><mo separator="true">,</mo><msub><mi>v</mi><mn>4</mn></msub></mrow><annotation encoding="application/x-tex">v_1, v_2, v_2, v_3, v_3, v_2, v_4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>] are converted to the same graph.</p><p id="91594a64-99bd-42a0-bbd2-81695105d94f" class="">Although in a particular dataset, the two sessions may produce the same next item, there may also exist a dataset in which the two sessions produce different next items. In the latter case, it is not possible for these GNN models to make correct recommendations for both sessions. Therefore, these models have a limitation in their modeling capacity.</p><p id="bcc66615-ebf3-4597-ad04-85f11e2ba8b2" class="">Lossy conversion could be problematic because the information ignored may be important to determine the next item. We should let the model automatically learn to decide what information can be ignored instead of “blindly” making the decision using a lossy conversion method. Otherwise, the model is not flexible enough to fit complex datasets since its modeling capacity is limited by the lossy conversion method.</p><h3 id="cc0ab3df-f6b0-4b89-bbef-6fdedc26bba9" class="">Oversmoothing Problem</h3><p id="1a6e35d1-2f23-4008-a7fb-1c866f280dac" class="">Over-smoothing is caused as they use only the embeddings updated through the last layer in the prediction layer. Specifically, as the number of layers increases, the embedding of a node will be influenced more from its neighbors’ embeddings. As a result, the embedding of a node in the last layer becomes similar to the embeddings of many directly/indirectly connected nodes. This phenomenon prevents most of the existing GCN-based methods from effectively utilizing the information of high-order neighborhood. Empirically, this is also shown by the fact that most of non-linear GCN-based methods show better performance when using only a few layers instead of deep networks.</p><p id="a15046db-e52e-4b11-9c8b-9643b15fbdb8" class="">Most common way to handle this is by <strong>Residual Prediction</strong> i.e. utilize the embeddings from all layers for prediction. After that, perform residual prediction, which predict each user’s preference to each item with the multiple embeddings from the multiple layers.</p><h2 id="84c5c609-a0c3-424d-8518-bb56be972bfc" class="">Tutorials</h2><h3 id="8c38e686-6be1-4176-8aaa-0d813ed88289" class="">SR-GNN Session-based Recommendation on Sample dataset</h3><p id="24b3e9a3-cc38-4628-8d09-44f31f9b61c4" class=""><a href="https://nbviewer.org/gist/sparsh-ai/9cc4447495dfd6465698b8d99afc2316">direct link to notebook →</a></p><figure id="49940283-07f1-4400-9bbd-cd6cf6bb19bf" class="image"><a href="Session-based%20Recommendation%20with%20Graph%20Neural%20Net%2091a6a42996db4e52b996402c9fa57cc3/Untitled%209.png"><img style="width:691px" src="Session-based%20Recommendation%20with%20Graph%20Neural%20Net%2091a6a42996db4e52b996402c9fa57cc3/Untitled%209.png"/></a></figure><h3 id="2b96f432-b169-4db7-917d-ad17362ab26b" class="">TAGNN Session-based Recommendation on Sample dataset</h3><p id="e0d71bda-10e9-4058-a23e-fffc0c1b7d70" class=""><a href="https://nbviewer.org/gist/sparsh-ai/64f5ed5f288b03693880ddf94b56b6c2">direct link to notebook →</a></p><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="ac4aabfd-7a82-40e4-adfe-ff7d3b26fd58"><div style="font-size:1.5em"><span class="icon">☝🏼</span></div><div style="width:100%">The flow diagram of this is same as SR-GNN, the difference is in the implementation of <code>SessionGraph() </code>module mainly.</div></figure><figure id="cda387fd-35dc-4f96-ad5b-b22f65be08ab" class="image"><a href="Session-based%20Recommendation%20with%20Graph%20Neural%20Net%2091a6a42996db4e52b996402c9fa57cc3/Untitled%2010.png"><img style="width:691px" src="Session-based%20Recommendation%20with%20Graph%20Neural%20Net%2091a6a42996db4e52b996402c9fa57cc3/Untitled%2010.png"/></a></figure><h3 id="daad3cd5-023f-4724-8887-f5cce31b767f" class="">TAGNN++ Session-based Recommendation on Diginetica and Yoochose dataset</h3><p id="0bc49ebc-f0d7-47d9-94ff-77f5edfdac0c" class=""><a href="https://nbviewer.org/gist/sparsh-ai/f506616b853cad89c76c8e3ca2e0c105">direct link to notebook (diginetica) →</a></p><p id="07896a47-720c-4eb5-b794-a30b92b23f9f" class=""><a href="https://nbviewer.org/gist/sparsh-ai/339575ed65f760ee2d9d21f3f977bb67">direct link to notebook (yoochoose) →</a></p><figure id="2528dcf7-9c64-4af4-9bba-26c42b268759" class="image"><a href="Session-based%20Recommendation%20with%20Graph%20Neural%20Net%2091a6a42996db4e52b996402c9fa57cc3/Untitled%2011.png"><img style="width:691px" src="Session-based%20Recommendation%20with%20Graph%20Neural%20Net%2091a6a42996db4e52b996402c9fa57cc3/Untitled%2011.png"/></a></figure><h3 id="431e1a7e-9b89-4290-ab3a-99383159da6e" class="">GC-SAN implementation in PyTorch</h3><p id="6dd8dede-b8c1-4ad7-8fb5-82f3c2906cfc" class=""><a href="https://nbviewer.org/gist/sparsh-ai/25d725cd3ffb43ef711fcd3ac13390a6">direct link to notebook →</a></p><figure id="e40c2b5a-128d-46a7-98cc-25b45b038255" class="image"><a href="Session-based%20Recommendation%20with%20Graph%20Neural%20Net%2091a6a42996db4e52b996402c9fa57cc3/Untitled%2012.png"><img style="width:479px" src="Session-based%20Recommendation%20with%20Graph%20Neural%20Net%2091a6a42996db4e52b996402c9fa57cc3/Untitled%2012.png"/></a></figure><h3 id="709167ff-a642-4544-a420-7c641fd28ef9" class="">LESSR Session-based Recommendation on Sample dataset</h3><p id="9c30ce46-e12d-46f7-93b7-44d1d0ffbb6a" class=""><a href="https://nbviewer.org/gist/sparsh-ai/2187689c8f2ecda58a0e5d5510f077ef">direct link to notebook →</a></p><figure id="14e4e501-bab2-4531-8581-5f5f76a55b31" class="image"><a href="Session-based%20Recommendation%20with%20Graph%20Neural%20Net%2091a6a42996db4e52b996402c9fa57cc3/Untitled%2013.png"><img style="width:662px" src="Session-based%20Recommendation%20with%20Graph%20Neural%20Net%2091a6a42996db4e52b996402c9fa57cc3/Untitled%2013.png"/></a></figure><h3 id="5698cef3-450f-4f46-9d46-90fa490137fa" class="">GCE-GNN Session-based Recommendation on Diginetica, Tmall and NowPlaying dataset</h3><p id="7d76f911-eba7-4cbe-904d-fad9f84c5144" class=""><a href="https://nbviewer.org/gist/sparsh-ai/0255e6fadc347db81ba360e8d2d571c4">direct link to notebook (diginetica)→</a> </p><p id="774ae59a-a398-4620-afe6-6c732619f36c" class=""><a href="https://nbviewer.org/gist/sparsh-ai/ac9c8e27612e9a4656f06376aa260d6a">direct link to notebook (tmall)→</a></p><p id="5a7632f6-33e6-4c88-9c57-4771781d8ac2" class=""><a href="https://nbviewer.org/gist/sparsh-ai/83ed18af8d234d9745cfd7b2ddaf8da0">direct link to notebook (nowplaying)→</a></p><figure id="ba9ff46a-cf24-42b4-9190-85e96b41801e" class="image"><a href="Session-based%20Recommendation%20with%20Graph%20Neural%20Net%2091a6a42996db4e52b996402c9fa57cc3/Untitled%2014.png"><img style="width:801px" src="Session-based%20Recommendation%20with%20Graph%20Neural%20Net%2091a6a42996db4e52b996402c9fa57cc3/Untitled%2014.png"/></a></figure><h3 id="44beba3b-ddee-4584-9e45-c1965e8b2e6c" class="">FGNN Session-based Recommendation on Sample dataset</h3><p id="42ee1a64-1029-40ae-9eed-7203cab13fcf" class=""><a href="https://nbviewer.org/gist/sparsh-ai/642d10ae901e3bb8b8821070ad689b71">direct link to notebook →</a></p><figure id="3be6c15b-ee46-483b-95bd-35a3efccd1c5" class="image"><a href="Session-based%20Recommendation%20with%20Graph%20Neural%20Net%2091a6a42996db4e52b996402c9fa57cc3/Untitled%2015.png"><img style="width:652px" src="Session-based%20Recommendation%20with%20Graph%20Neural%20Net%2091a6a42996db4e52b996402c9fa57cc3/Untitled%2015.png"/></a></figure><h3 id="dd0e0535-5983-469b-81ff-2c7736bd00e7" class="">Conversion of sessions into Session graph on Yoochoose dataset</h3><p id="80f15e1f-e98a-4f83-acc0-af95f8622f46" class=""><a href="https://nbviewer.org/gist/sparsh-ai/d732e7c3cf42dc5f26c551cd88b8641c">direct link to notebook →</a></p><h3 id="31668130-0b7c-4e00-b78e-315047352eab" class="">Session graph with attention in PyTorch</h3><p id="876cfbce-b5bd-4cdd-9190-cb288b771bdd" class=""><a href="https://gist.github.com/sparsh-ai/a47acac562c6801f4bd37196e251fd88">direct link to notebook →</a></p><h3 id="500d87c9-3906-493b-8ba7-2382f14c8354" class="">Preprocessing of session datasets</h3><p id="a2f4963b-a9b5-4c7c-b28a-aaaedaac748d" class=""><a href="https://nbviewer.org/gist/sparsh-ai/12d1f5ca07add606f27b0f841b550a82">direct link to notebook (sample data)→</a></p><p id="249188a9-110b-4423-9384-62580cd0183f" class=""><a href="https://nbviewer.org/gist/sparsh-ai/fbaf4627cbd3fe5b45efc2f6ab50920a">direct link to notebook (diginetica)→</a></p><p id="ff269520-bbea-4cea-9542-c8f2ac0b024a" class=""><a href="https://nbviewer.org/gist/sparsh-ai/43b1bfb234971380b4f3179244bc25f5">direct link to notebook (gowalla)→</a></p><p id="e119ea0c-295f-41d0-887f-a99cbe018bbc" class=""><a href="https://nbviewer.org/gist/sparsh-ai/512750bd6427d98ca396d041abf421ac">direct link to notebook (lastfm)→</a></p><hr id="a64a2a76-177a-473b-bfa8-a3c9faf361b8"/></div></article></body></html>